{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "MNIST(types of NN)_Rohit_Roy_Chowdhury.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykORlzQmrHbE"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tensorflow.keras import regularizers\n",
        "import random\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4x7AN7Z6rHbH",
        "outputId": "e799aa02-9b14-480e-b8c7-9ad0df427ac7"
      },
      "source": [
        "data = tf.keras.datasets.mnist.load_data(path=\"mnist.npz\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "agcDPhKSrHbI",
        "outputId": "d36d275e-b216-4428-aa32-ee34cd22481d"
      },
      "source": [
        "img = data[0][0][1]\n",
        "pixels = np.asarray(img)\n",
        "print(pixels.shape)\n",
        "plt.imshow(pixels, cmap='gray')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f1b602f3e90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nG-QJ-CrHbJ",
        "outputId": "80672162-d19f-4f32-b135-37a14de9e733"
      },
      "source": [
        "train_images = data[0][0]/255.0\n",
        "train_labels = data[0][1]\n",
        "test_images = data[1][0]/255.0\n",
        "test_labels = data[1][1]\n",
        "print(type(train_labels))\n",
        "print(type(train_labels[0]))\n",
        "print(test_images.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.uint8'>\n",
            "(10000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TD_OBwY4rHbJ",
        "outputId": "c4709137-a9c2-4fd7-efdd-45c1b2bd0453"
      },
      "source": [
        "train_images = np.expand_dims(train_images, -1)\n",
        "test_images = np.expand_dims(test_images, -1)\n",
        "print(test_images[0].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAEEFHGsrHbJ"
      },
      "source": [
        "#training in LeNet-5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOzvfbLsrHbK"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation ='relu', input_shape=(28,28,1), padding='same'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation ='relu', input_shape=(28,28,1), padding='same'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation = 'relu'),\n",
        "    tf.keras.layers.Dense(256, activation = 'relu'),\n",
        "    tf.keras.layers.Dense(128, activation = 'relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer= 'adam', loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'] )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BV4H0uT7rHbL",
        "outputId": "5cf7e403-3792-4734-d627-4534d0b2fc54"
      },
      "source": [
        "model.fit(train_images, train_labels, epochs = 50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/backend.py:4930: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  '\"`sparse_categorical_crossentropy` received `from_logits=True`, but '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1875/1875 [==============================] - 90s 48ms/step - loss: 0.1243 - accuracy: 0.9605\n",
            "Epoch 2/50\n",
            "1875/1875 [==============================] - 89s 47ms/step - loss: 0.0460 - accuracy: 0.9859\n",
            "Epoch 3/50\n",
            "1875/1875 [==============================] - 89s 48ms/step - loss: 0.0324 - accuracy: 0.9906\n",
            "Epoch 4/50\n",
            "1875/1875 [==============================] - 89s 47ms/step - loss: 0.0232 - accuracy: 0.9936\n",
            "Epoch 5/50\n",
            "1875/1875 [==============================] - 89s 47ms/step - loss: 0.0205 - accuracy: 0.9943\n",
            "Epoch 6/50\n",
            "1875/1875 [==============================] - 88s 47ms/step - loss: 0.0154 - accuracy: 0.9953\n",
            "Epoch 7/50\n",
            "1875/1875 [==============================] - 88s 47ms/step - loss: 0.0130 - accuracy: 0.9960\n",
            "Epoch 8/50\n",
            "1875/1875 [==============================] - 88s 47ms/step - loss: 0.0116 - accuracy: 0.9969\n",
            "Epoch 9/50\n",
            "1875/1875 [==============================] - 89s 47ms/step - loss: 0.0097 - accuracy: 0.9972\n",
            "Epoch 10/50\n",
            "1875/1875 [==============================] - 88s 47ms/step - loss: 0.0117 - accuracy: 0.9967\n",
            "Epoch 11/50\n",
            "1875/1875 [==============================] - 88s 47ms/step - loss: 0.0068 - accuracy: 0.9982\n",
            "Epoch 12/50\n",
            "1875/1875 [==============================] - 88s 47ms/step - loss: 0.0097 - accuracy: 0.9976\n",
            "Epoch 13/50\n",
            "1875/1875 [==============================] - 88s 47ms/step - loss: 0.0062 - accuracy: 0.9984\n",
            "Epoch 14/50\n",
            "1875/1875 [==============================] - 88s 47ms/step - loss: 0.0079 - accuracy: 0.9978\n",
            "Epoch 15/50\n",
            "1875/1875 [==============================] - 89s 47ms/step - loss: 0.0072 - accuracy: 0.9983\n",
            "Epoch 16/50\n",
            "1875/1875 [==============================] - 89s 48ms/step - loss: 0.0075 - accuracy: 0.9982\n",
            "Epoch 17/50\n",
            "1875/1875 [==============================] - 90s 48ms/step - loss: 0.0066 - accuracy: 0.9985\n",
            "Epoch 18/50\n",
            "1875/1875 [==============================] - 90s 48ms/step - loss: 0.0073 - accuracy: 0.9984\n",
            "Epoch 19/50\n",
            "1875/1875 [==============================] - 90s 48ms/step - loss: 0.0068 - accuracy: 0.9985\n",
            "Epoch 20/50\n",
            "1875/1875 [==============================] - 89s 48ms/step - loss: 0.0045 - accuracy: 0.9991\n",
            "Epoch 21/50\n",
            "1875/1875 [==============================] - 90s 48ms/step - loss: 0.0044 - accuracy: 0.9989\n",
            "Epoch 22/50\n",
            "1875/1875 [==============================] - 90s 48ms/step - loss: 0.0046 - accuracy: 0.9991\n",
            "Epoch 23/50\n",
            "1875/1875 [==============================] - 90s 48ms/step - loss: 0.0049 - accuracy: 0.9989\n",
            "Epoch 24/50\n",
            "1875/1875 [==============================] - 90s 48ms/step - loss: 0.0059 - accuracy: 0.9988\n",
            "Epoch 25/50\n",
            "1875/1875 [==============================] - 92s 49ms/step - loss: 0.0060 - accuracy: 0.9988\n",
            "Epoch 26/50\n",
            "1875/1875 [==============================] - 91s 49ms/step - loss: 0.0066 - accuracy: 0.9987\n",
            "Epoch 27/50\n",
            "1875/1875 [==============================] - 91s 48ms/step - loss: 0.0059 - accuracy: 0.9987\n",
            "Epoch 28/50\n",
            "1875/1875 [==============================] - 92s 49ms/step - loss: 0.0035 - accuracy: 0.9992\n",
            "Epoch 29/50\n",
            "1875/1875 [==============================] - 92s 49ms/step - loss: 0.0064 - accuracy: 0.9987\n",
            "Epoch 30/50\n",
            "1875/1875 [==============================] - 91s 49ms/step - loss: 0.0037 - accuracy: 0.9992\n",
            "Epoch 31/50\n",
            "1875/1875 [==============================] - 91s 48ms/step - loss: 0.0046 - accuracy: 0.9990\n",
            "Epoch 32/50\n",
            "1875/1875 [==============================] - 90s 48ms/step - loss: 0.0047 - accuracy: 0.9990\n",
            "Epoch 33/50\n",
            "1875/1875 [==============================] - 90s 48ms/step - loss: 0.0071 - accuracy: 0.9987\n",
            "Epoch 34/50\n",
            "1875/1875 [==============================] - 90s 48ms/step - loss: 0.0049 - accuracy: 0.9991\n",
            "Epoch 35/50\n",
            "1875/1875 [==============================] - 90s 48ms/step - loss: 0.0038 - accuracy: 0.9993\n",
            "Epoch 36/50\n",
            "1875/1875 [==============================] - 90s 48ms/step - loss: 0.0047 - accuracy: 0.9990\n",
            "Epoch 37/50\n",
            "1875/1875 [==============================] - 90s 48ms/step - loss: 0.0080 - accuracy: 0.9987\n",
            "Epoch 38/50\n",
            "1875/1875 [==============================] - 90s 48ms/step - loss: 0.0016 - accuracy: 0.9998\n",
            "Epoch 39/50\n",
            "1875/1875 [==============================] - 90s 48ms/step - loss: 0.0059 - accuracy: 0.9991\n",
            "Epoch 40/50\n",
            "1875/1875 [==============================] - 90s 48ms/step - loss: 0.0051 - accuracy: 0.9993\n",
            "Epoch 41/50\n",
            "1875/1875 [==============================] - 90s 48ms/step - loss: 0.0062 - accuracy: 0.9988\n",
            "Epoch 42/50\n",
            "1875/1875 [==============================] - 90s 48ms/step - loss: 8.8993e-04 - accuracy: 0.9998\n",
            "Epoch 43/50\n",
            "1875/1875 [==============================] - 90s 48ms/step - loss: 0.0079 - accuracy: 0.9991\n",
            "Epoch 44/50\n",
            "1875/1875 [==============================] - 90s 48ms/step - loss: 0.0030 - accuracy: 0.9994\n",
            "Epoch 45/50\n",
            "1875/1875 [==============================] - 91s 49ms/step - loss: 0.0069 - accuracy: 0.9990\n",
            "Epoch 46/50\n",
            "1875/1875 [==============================] - 91s 49ms/step - loss: 0.0041 - accuracy: 0.9994\n",
            "Epoch 47/50\n",
            "1875/1875 [==============================] - 90s 48ms/step - loss: 0.0035 - accuracy: 0.9994\n",
            "Epoch 48/50\n",
            "1875/1875 [==============================] - 90s 48ms/step - loss: 0.0052 - accuracy: 0.9992\n",
            "Epoch 49/50\n",
            "1875/1875 [==============================] - 90s 48ms/step - loss: 0.0036 - accuracy: 0.9995\n",
            "Epoch 50/50\n",
            "1875/1875 [==============================] - 90s 48ms/step - loss: 0.0076 - accuracy: 0.9990\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1b60f52ad0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXlNJw-7rHbN",
        "outputId": "65534c82-a356-493b-a846-cdd82b6e7350"
      },
      "source": [
        "test_loss, test_acc = model.evaluate( test_images, test_labels, verbose=0 )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/backend.py:4930: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  '\"`sparse_categorical_crossentropy` received `from_logits=True`, but '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNLXr9lerHbN",
        "outputId": "80bde48e-b96e-4702-f8bf-cea3dd3da0dd"
      },
      "source": [
        "print(\"Accuracy %2f \"%test_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy 0.990100 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sTwzv74rHbO",
        "outputId": "25fa5b7b-143d-4a6a-ccd7-793018f7c8ce"
      },
      "source": [
        "#training in AlexNet\n",
        "train_images = data[0][0]/255.0\n",
        "train_labels = data[0][1]\n",
        "test_images = data[1][0]/255.0\n",
        "test_labels = data[1][1]\n",
        "x_train = tf.expand_dims(train_images, axis=3, name=None)\n",
        "x_test = tf.expand_dims(test_images, axis=3, name=None)\n",
        "x_train = tf.repeat(x_train, 3, axis=3)\n",
        "x_test = tf.repeat(x_test, 3, axis=3)\n",
        "print(x_train[0].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(28, 28, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yo6_wc1HrHbP"
      },
      "source": [
        "\n",
        "model2 = tf.keras.Sequential([\n",
        "    tf.keras.layers.experimental.preprocessing.Resizing(224, 224, interpolation=\"bilinear\", input_shape=x_train.shape[1:]),\n",
        "    tf.keras.layers.Conv2D(96, 11, strides=4, padding='same'),\n",
        "    tf.keras.layers.Lambda(tf.nn.local_response_normalization),\n",
        "    tf.keras.layers.Activation('relu'),\n",
        "    tf.keras.layers.MaxPooling2D(3, strides=2),\n",
        "    tf.keras.layers.Conv2D(256, 5, strides=4, padding='same'),\n",
        "    tf.keras.layers.Lambda(tf.nn.local_response_normalization),\n",
        "    tf.keras.layers.Activation('relu'),\n",
        "    tf.keras.layers.MaxPooling2D(3, strides=2),\n",
        "    tf.keras.layers.Conv2D(384, 3, strides=4, padding='same'),\n",
        "    tf.keras.layers.Activation('relu'),\n",
        "    tf.keras.layers.Conv2D(256, 3, strides=4, padding='same'),\n",
        "    tf.keras.layers.Activation('relu'),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(4096, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(4096, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model2.compile(optimizer= 'adam', loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'] )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbCZGX7_-cYu",
        "outputId": "1aee89ba-8cf0-40a7-cc3e-30478bbdda50"
      },
      "source": [
        "model2.fit(x_train, train_labels, epochs = 50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/backend.py:4930: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  '\"`sparse_categorical_crossentropy` received `from_logits=True`, but '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1875/1875 [==============================] - 1715s 914ms/step - loss: 0.3006 - accuracy: 0.8995\n",
            "Epoch 2/50\n",
            "1875/1875 [==============================] - 1722s 918ms/step - loss: 0.0895 - accuracy: 0.9766\n",
            "Epoch 3/50\n",
            "1875/1875 [==============================] - 1731s 923ms/step - loss: 0.0733 - accuracy: 0.9811\n",
            "Epoch 4/50\n",
            "1875/1875 [==============================] - 1739s 928ms/step - loss: 0.0561 - accuracy: 0.9858\n",
            "Epoch 5/50\n",
            "1875/1875 [==============================] - 1738s 927ms/step - loss: 0.0477 - accuracy: 0.9877\n",
            "Epoch 6/50\n",
            "1875/1875 [==============================] - 1748s 932ms/step - loss: 0.0419 - accuracy: 0.9899\n",
            "Epoch 7/50\n",
            "1875/1875 [==============================] - 1740s 928ms/step - loss: 0.0387 - accuracy: 0.9905\n",
            "Epoch 8/50\n",
            "1875/1875 [==============================] - 1745s 931ms/step - loss: 0.0332 - accuracy: 0.9916\n",
            "Epoch 9/50\n",
            "1875/1875 [==============================] - 1732s 924ms/step - loss: 0.0335 - accuracy: 0.9916\n",
            "Epoch 10/50\n",
            "1875/1875 [==============================] - 1738s 927ms/step - loss: 0.0288 - accuracy: 0.9930\n",
            "Epoch 11/50\n",
            "1875/1875 [==============================] - 1724s 920ms/step - loss: 0.0285 - accuracy: 0.9936\n",
            "Epoch 12/50\n",
            "1875/1875 [==============================] - 1722s 918ms/step - loss: 0.0268 - accuracy: 0.9933\n",
            "Epoch 13/50\n",
            "1875/1875 [==============================] - 1725s 920ms/step - loss: 0.0253 - accuracy: 0.9937\n",
            "Epoch 14/50\n",
            "1875/1875 [==============================] - 1719s 917ms/step - loss: 0.0238 - accuracy: 0.9945\n",
            "Epoch 15/50\n",
            "1875/1875 [==============================] - 1718s 916ms/step - loss: 0.0220 - accuracy: 0.9951\n",
            "Epoch 16/50\n",
            "1875/1875 [==============================] - 1716s 915ms/step - loss: 0.0212 - accuracy: 0.9954\n",
            "Epoch 17/50\n",
            "1875/1875 [==============================] - 1704s 909ms/step - loss: 0.0186 - accuracy: 0.9955\n",
            "Epoch 18/50\n",
            "1875/1875 [==============================] - 1694s 903ms/step - loss: 0.0186 - accuracy: 0.9957\n",
            "Epoch 19/50\n",
            "1875/1875 [==============================] - 1695s 904ms/step - loss: 0.0204 - accuracy: 0.9958\n",
            "Epoch 20/50\n",
            "1875/1875 [==============================] - 1704s 909ms/step - loss: 0.0158 - accuracy: 0.9965\n",
            "Epoch 21/50\n",
            "1875/1875 [==============================] - 1701s 907ms/step - loss: 0.0227 - accuracy: 0.9956\n",
            "Epoch 22/50\n",
            "1875/1875 [==============================] - 1704s 909ms/step - loss: 0.0174 - accuracy: 0.9961\n",
            "Epoch 23/50\n",
            " 292/1875 [===>..........................] - ETA: 24:01 - loss: 0.0163 - accuracy: 0.9974"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PEED_5w-ybA"
      },
      "source": [
        "test_loss, test_acc = model.evaluate( test_images, test_labels, verbose=0 )\n",
        "print(\"Accuracy %2f \"%test_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYA2lKNKy3Q9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}